{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "========================================================\n",
    "Import single subject from LIMO data set into MNE-Python\n",
    "========================================================\n",
    "\n",
    "Here we a define function to extract the eeg signal data\n",
    "from the LIMO structures in the LIMO dataset, see [1]_, [2]_, and:\n",
    "\n",
    "    https://datashare.is.ed.ac.uk/handle/10283/2189?show=full\n",
    "\n",
    "    https://github.com/LIMO-EEG-Toolbox\n",
    "\n",
    "The code allows to:\n",
    "\n",
    "Fetch single subjects epochs data for the LIMO data set.\n",
    "Epochs information (i.e., sampling rate, number of epochs per condition,\n",
    "number and name of EEG channels per subject, etc.) is extracted from\n",
    "the LIMO .mat files stored on disk.\n",
    "If files are not found, the function mne.datasets.limo.load_data() will\n",
    "automatically download the data from a remote repository.\n",
    "\n",
    ":func:`mne.datasets.limo.load_data` creates a custom info and\n",
    "epochs structure in MNE-Python.\n",
    "Missing channels can be interpolated if desired.\n",
    "\n",
    "\n",
    "References\n",
    "----------\n",
    ".. [1] Guillaume, Rousselet. (2016). LIMO EEG Dataset, [dataset].\n",
    "       University of Edinburgh, Centre for Clinical Brain Sciences.\n",
    "       https://doi.org/10.7488/ds/1556.\n",
    ".. [2] Rousselet, G. A., Gaspar, C. M., Pernet, C. R., Husk, J. S.,\n",
    "       Bennett, P. J., & Sekuler, A. B. (2010). Healthy aging delays scalp EEG\n",
    "       sensitivity to noise in a face discrimination task.\n",
    "       Frontiers in psychology, 1, 19. https://doi.org/10.3389/fpsyg.2010.00019\n",
    "\"\"\"\n",
    "\n",
    "# Authors: Jose C. Garcia Alanis <alanis.jcg@gmail.com>\n",
    "#\n",
    "# License: BSD (3-clause)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import mne\n",
    "from mne.datasets import limo\n",
    "from mne.stats import linear_regression\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "# fetch data from subject 2 and interpolate missing channels\n",
    "limo_epochs = limo.load_data(subject=2)\n",
    "\n",
    "###############################################################################\n",
    "# In the original LIMO experiment, participants performed a two-alternative\n",
    "# forced choice task discriminating between the same two faces.\n",
    "# The critical manipulation in the experiment was that the phase-coherence of\n",
    "# the presented face-stimuli was varied across a noise-signal continuum\n",
    "# spanning from 0 to 100 %. In other words, faces with high phase coherence\n",
    "# were easily discernible, while faces with low phase-coherence were hard to\n",
    "# identify as such).\n",
    "# The events coding the presentation of each of these two faces are stored in\n",
    "# ``limo_epochs.events``.\n",
    "#\n",
    "# We can visualise the distribution of the face events contained in the\n",
    "# epochs structure. Events should appear clearly grouped, as they are ordered\n",
    "# during the import process.\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "mne.viz.plot_events(limo_epochs.events, event_id=limo_epochs.event_id, axes=ax)\n",
    "ax.set(title=\"Distribution of events\")\n",
    "plt.legend(loc='lower left', borderaxespad=1.)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "###############################################################################\n",
    "# As it can be seen above, events are coded as ``Face/A`` and ``Face/B``.\n",
    "# Information about the phase-coherence of the presented faces is stored in\n",
    "# ``limo_epochs.metadata``, which also contains information about the presented\n",
    "# faces for convenience.\n",
    "#\n",
    "# Check epochs metadata\n",
    "print(limo_epochs.metadata.head())\n",
    "\n",
    "###############################################################################\n",
    "# Before going on, we'll drop the EOG channels present in the LIMO epochs\n",
    "# (coded with EXG-prefix in ``limo_epochs.info['ch_names']``, as data has\n",
    "# already been cleaned.\n",
    "limo_epochs.drop_channels(['EXG1', 'EXG2', 'EXG3', 'EXG4'])\n",
    "\n",
    "# Furthermore, some datasets contain missing channels (stored in\n",
    "# ``limo_epochs.info[‘bads’]``), which were dropped during preprocessing of the\n",
    "# data. We’ll interpolate this channels for convenience.\n",
    "limo_epochs.interpolate_bads(reset_bads=True)\n",
    "\n",
    "###############################################################################\n",
    "# Now we can go ahead and plot the ERPs evoked by Face A and Face B\n",
    "\n",
    "# only show -250 to 500 ms\n",
    "ts_args = dict(xlim=(-.25, 0.5))\n",
    "\n",
    "# plot evoked response for faces A & B\n",
    "limo_epochs['Face/A'].average().plot_joint(times=[.15],\n",
    "                                           title='Evoked response: Face A',\n",
    "                                           ts_args=ts_args)\n",
    "\n",
    "limo_epochs['Face/B'].average().plot_joint(times=[.15],\n",
    "                                           title='Evoked response: Face B',\n",
    "                                           ts_args=ts_args)\n",
    "\n",
    "###############################################################################\n",
    "# We can also compute the difference wave contrasting Face A and Face B.\n",
    "# Although, looking at the evoked responses above, we shouldn't expect great\n",
    "# differences among these face-stimuli.\n",
    "#\n",
    "# Compute difference wave (Face A minus Face B)\n",
    "difference_wave = mne.combine_evoked([limo_epochs['Face/A'].average(),\n",
    "                                     -limo_epochs['Face/B'].average()],\n",
    "                                     weights='equal')\n",
    "\n",
    "# Plot difference between Face A and Face B\n",
    "difference_wave.plot_joint(times=[.15], title='Difference Face A - Face B')\n",
    "\n",
    "###############################################################################\n",
    "# As expected, no see clear differential patterns appears when contrasting\n",
    "# Face A and Face B. However, we could narrow our search to\n",
    "# since this is a \"visual paradigm\" it might be best to electrodes located over\n",
    "# the occipital lobe. After all this is \"visual paradigm\". Thus, differences\n",
    "# between stimuli (if any) might easier to spot over \"more visual areas\".\n",
    "#\n",
    "# Create a dictionary containing the evoked responses\n",
    "conditions = [\"Face/A\", \"Face/B\"]\n",
    "evoked_dict = dict()\n",
    "for condition in conditions:\n",
    "    evoked_dict[condition] = limo_epochs[condition].average()\n",
    "print(evoked_dict)\n",
    "\n",
    "# concentrate on an occipital electrode\n",
    "pick = evoked_dict[\"Face/A\"].ch_names.index('B11')\n",
    "\n",
    "# compare evoked responses\n",
    "mne.viz.plot_compare_evokeds(evoked_dict, picks=pick)\n",
    "\n",
    "###############################################################################\n",
    "# Next, we can inspect the effect of phase-coherence on the activation\n",
    "# patterns evoked by the presented face-stimuli.\n",
    "# Here, one would expect that faces with high phase-coherence evoke a stronger\n",
    "# response, as participants should be better at identifying these faces.\n",
    "#\n",
    "# Create design matrix for linear regression. We'll use the information\n",
    "# contained in the ``limo_epochs.metadata``.\n",
    "design = limo_epochs.metadata.copy()\n",
    "design = design.assign(intercept=1)  # add intercept\n",
    "design['face a - face b'] = np.where(design['face'] == 'A', 1, -1)\n",
    "names = ['intercept', 'face a - face b', 'phase-coherence']\n",
    "\n",
    "# fit linear model\n",
    "reg = linear_regression(limo_epochs, design[names], names=names)\n",
    "\n",
    "###############################################################################\n",
    "# Visualise effect of phase-coherence.\n",
    "reg['phase-coherence'].beta.plot_joint(ts_args=ts_args,\n",
    "                                       title='Effect of phase-coherence',\n",
    "                                       times=[.23])\n",
    "\n",
    "###############################################################################\n",
    "# Here we can see a clear effect of phase-coherence, with higher\n",
    "# phase-coherence (i.e., better \"face visibility\") being associated with\n",
    "# stronger activity patterns.\n",
    "\n",
    "###############################################################################\n",
    "# Conversely, there appears to be no (or very small) systematic effects when\n",
    "# constraining Face A and Face B. This is largely consistent with the\n",
    "# difference wave approach presented above.\n",
    "#\n",
    "# Visualise effect of face condition (Face A vs. Face B).\n",
    "reg['face a - face b'].beta.plot_joint(title='Contrast: Face A - Face B',\n",
    "                                       ts_args=ts_args,\n",
    "                                       times=[.15])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
