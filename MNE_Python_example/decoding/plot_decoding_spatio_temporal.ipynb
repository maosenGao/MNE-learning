{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    ".. _tut_dec_st_source:\n",
    "\n",
    "==========================\n",
    "Decoding source space data\n",
    "==========================\n",
    "\n",
    "Decoding to MEG data in source space on the left cortical surface. Here\n",
    "univariate feature selection is employed for speed purposes to confine the\n",
    "classification to a small number of potentially relevant features. The\n",
    "classifier then is trained to selected features of epochs in source space.\n",
    "\"\"\"\n",
    "# sphinx_gallery_thumbnail_number = 2\n",
    "\n",
    "# Author: Denis A. Engemann <denis.engemann@gmail.com>\n",
    "#         Alexandre Gramfort <alexandre.gramfort@inria.fr>\n",
    "#         Jean-Remi King <jeanremi.king@gmail.com>\n",
    "#         Eric Larson <larson.eric.d@gmail.com>\n",
    "#\n",
    "# License: BSD (3-clause)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import mne\n",
    "from mne.minimum_norm import apply_inverse_epochs, read_inverse_operator\n",
    "from mne.decoding import (cross_val_multiscore, LinearModel, SlidingEstimator,\n",
    "                          get_coef)\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "data_path = mne.datasets.sample.data_path()\n",
    "fname_fwd = data_path + 'MEG/sample/sample_audvis-meg-oct-6-fwd.fif'\n",
    "fname_evoked = data_path + '/MEG/sample/sample_audvis-ave.fif'\n",
    "subjects_dir = data_path + '/subjects'\n",
    "\n",
    "###############################################################################\n",
    "# Set parameters\n",
    "raw_fname = data_path + '/MEG/sample/sample_audvis_filt-0-40_raw.fif'\n",
    "event_fname = data_path + '/MEG/sample/sample_audvis_filt-0-40_raw-eve.fif'\n",
    "fname_cov = data_path + '/MEG/sample/sample_audvis-cov.fif'\n",
    "fname_inv = data_path + '/MEG/sample/sample_audvis-meg-oct-6-meg-inv.fif'\n",
    "\n",
    "tmin, tmax = -0.2, 0.8\n",
    "event_id = dict(aud_r=2, vis_r=4)  # load contra-lateral conditions\n",
    "\n",
    "# Setup for reading the raw data\n",
    "raw = mne.io.read_raw_fif(raw_fname, preload=True)\n",
    "raw.filter(None, 10., fir_design='firwin')\n",
    "events = mne.read_events(event_fname)\n",
    "\n",
    "# Set up pick list: MEG - bad channels (modify to your needs)\n",
    "raw.info['bads'] += ['MEG 2443']  # mark bads\n",
    "picks = mne.pick_types(raw.info, meg=True, eeg=False, stim=True, eog=True,\n",
    "                       exclude='bads')\n",
    "\n",
    "# Read epochs\n",
    "epochs = mne.Epochs(raw, events, event_id, tmin, tmax, proj=True,\n",
    "                    picks=picks, baseline=(None, 0), preload=True,\n",
    "                    reject=dict(grad=4000e-13, eog=150e-6),\n",
    "                    decim=5)  # decimate to save memory and increase speed\n",
    "\n",
    "###############################################################################\n",
    "# Compute inverse solution\n",
    "snr = 3.0\n",
    "noise_cov = mne.read_cov(fname_cov)\n",
    "inverse_operator = read_inverse_operator(fname_inv)\n",
    "\n",
    "stcs = apply_inverse_epochs(epochs, inverse_operator,\n",
    "                            lambda2=1.0 / snr ** 2, verbose=False,\n",
    "                            method=\"dSPM\", pick_ori=\"normal\")\n",
    "\n",
    "###############################################################################\n",
    "# Decoding in sensor space using a logistic regression\n",
    "\n",
    "# Retrieve source space data into an array\n",
    "X = np.array([stc.lh_data for stc in stcs])  # only keep left hemisphere\n",
    "y = epochs.events[:, 2]\n",
    "\n",
    "# prepare a series of classifier applied at each time sample\n",
    "clf = make_pipeline(StandardScaler(),  # z-score normalization\n",
    "                    SelectKBest(f_classif, k=500),  # select features for speed\n",
    "                    LinearModel(LogisticRegression(C=1, solver='liblinear')))\n",
    "time_decod = SlidingEstimator(clf, scoring='roc_auc')\n",
    "\n",
    "# Run cross-validated decoding analyses:\n",
    "scores = cross_val_multiscore(time_decod, X, y, cv=5, n_jobs=1)\n",
    "\n",
    "# Plot average decoding scores of 5 splits\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.plot(epochs.times, scores.mean(0), label='score')\n",
    "ax.axhline(.5, color='k', linestyle='--', label='chance')\n",
    "ax.axvline(0, color='k')\n",
    "plt.legend()\n",
    "\n",
    "###############################################################################\n",
    "# To investigate weights, we need to retrieve the patterns of a fitted model\n",
    "\n",
    "# The fitting needs not be cross validated because the weights are based on\n",
    "# the training sets\n",
    "time_decod.fit(X, y)\n",
    "\n",
    "# Retrieve patterns after inversing the z-score normalization step:\n",
    "patterns = get_coef(time_decod, 'patterns_', inverse_transform=True)\n",
    "\n",
    "stc = stcs[0]  # for convenience, lookup parameters from first stc\n",
    "vertices = [stc.lh_vertno, np.array([], int)]  # empty array for right hemi\n",
    "stc_feat = mne.SourceEstimate(np.abs(patterns), vertices=vertices,\n",
    "                              tmin=stc.tmin, tstep=stc.tstep, subject='sample')\n",
    "\n",
    "brain = stc_feat.plot(views=['lat'], transparent=True,\n",
    "                      initial_time=0.1, time_unit='s',\n",
    "                      subjects_dir=subjects_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
